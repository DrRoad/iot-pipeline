{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection using LSTM\n",
    "\n",
    "This notebook is an example for how to use Long-Short Term Memory neural networks for anomaly detection.\n",
    "\n",
    "Data used in this example is taken from hardware sensors attached to a robot arm performing simple tasks. We will be using 3 values - linear acceleration X/Y/Z. The goal is to predict robot malfunction before it crashes (and before a person is able to notice it).\n",
    "\n",
    "Network graph will be prepared using Keras/Tensorflow and the training itself will be performed using DeepWater."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required modules (h2o for deepwater and pandas for initial data munging).\n",
    "\n",
    "Bootstrap a single node H2O instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.estimators.deepwater import H2ODeepWaterEstimator\n",
    "\n",
    "h2o.init(port=54321, nthreads=-1)\n",
    "if not H2ODeepWaterEstimator.available(): exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back):\n",
    "    dataX = []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = np.append(dataset[i:(i+look_back),], [random.randint(0, 1000)/1e+20])\n",
    "        dataX.append(a)\n",
    "    return np.array(dataX)\n",
    "\n",
    "# Read training data into memory\n",
    "iot_raw = pd.read_csv('../model-builder/resources/normal_20170202_2229.csv')\n",
    "\n",
    "# Select training columns\n",
    "iot_train = iot_raw[[\" LinAccX (g)\",\" LinAccY (g)\",\" LinAccZ (g)\"]].as_matrix()\n",
    "\n",
    "features = 3\n",
    "look_back = 20\n",
    "\n",
    "iot_train = create_dataset(iot_train, look_back)\n",
    "\n",
    "# Send the data to H2O\n",
    "iot_train_frame  = h2o.H2OFrame(iot_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom TF LSTM model\n",
    "\n",
    "Build a custom LSTM network graph using Keras and save it for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers import LSTM, RepeatVector\n",
    "from keras import backend as K\n",
    "from keras.objectives import categorical_crossentropy\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.training.rmsprop import RMSPropOptimizer\n",
    "\n",
    "def keras_model(look_back, features, batch_size=1):\n",
    "    input_dim = look_back * features\n",
    "    latent_dim = 2\n",
    "\n",
    "    classes = 1\n",
    "    # always create a new graph inside ipython or\n",
    "    # the default one will be used and can lead to\n",
    "    # unexpected behavior\n",
    "    graph = tf.Graph() \n",
    "    with graph.as_default():\n",
    "        # Input images fed via H2O\n",
    "        inp = tf.placeholder(tf.float32, [None, input_dim])\n",
    "        # Actual labels used for training fed via H2O\n",
    "        labels = tf.placeholder(tf.float32, [None, classes])\n",
    "        \n",
    "        # Keras network\n",
    "        inputs = Reshape((look_back, features))(inp)\n",
    "\n",
    "        encoded = LSTM(latent_dim, input_shape=(look_back, input_dim))(inputs)\n",
    "        \n",
    "        decoded = RepeatVector(look_back)(encoded)\n",
    "        decoded = LSTM(features, return_sequences=True)(decoded)\n",
    "        \n",
    "        softmax = tf.nn.softmax_cross_entropy_with_logits(labels=inputs,logits=decoded)\n",
    "        softmax = tf.reshape(softmax, [-1, batch_size, look_back])\n",
    "        \n",
    "        predictions = tf.reshape(tf.reduce_mean(softmax, axis=2), [batch_size, classes])\n",
    "        \n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=inputs,logits=decoded))\n",
    "        \n",
    "        train_step = RMSPropOptimizer(1.0).minimize(loss)\n",
    "\n",
    "        init_op = tf.global_variables_initializer()\n",
    "\n",
    "        # Metadata required by H2O\n",
    "        tf.add_to_collection(ops.GraphKeys.INIT_OP, init_op.name)\n",
    "        tf.add_to_collection(ops.GraphKeys.TRAIN_OP, train_step)\n",
    "        tf.add_to_collection(\"logits\", decoded)\n",
    "        tf.add_to_collection(\"predictions\", predictions)\n",
    "\n",
    "        meta = json.dumps({\n",
    "                \"inputs\": {\"batch_image_input\": inp.name,\n",
    "                           \"categorical_labels\": labels.name},\n",
    "                \"outputs\": {\"categorical_logits\": decoded.name,\n",
    "                            \"layers\": ','.join([m.name for m in tf.get_default_graph().get_operations()])},\n",
    "                \"parameters\": {}\n",
    "            })\n",
    "        tf.add_to_collection(\"meta\", meta)\n",
    "\n",
    "        # Save the meta file with the graph\n",
    "        saver = tf.train.Saver()\n",
    "        filename = \"/tmp/keras_tf_lstm.meta\"\n",
    "        tf.train.export_meta_graph(filename, saver_def=saver.as_saver_def())\n",
    "\n",
    "        return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "model_filename = keras_model(look_back, features, batch_size)\n",
    "model = H2ODeepWaterEstimator(epochs=100, \n",
    "                              network_definition_file=model_filename,\n",
    "                              backend=\"tensorflow\",\n",
    "                              mini_batch_size = batch_size,\n",
    "                              standardize=False\n",
    "                             ) \n",
    "%time model.train(x = list(range(look_back * features)), y = look_back * features, training_frame=iot_train_frame)\n",
    "model.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(iot_train_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.std(preds[\"predict\"].as_data_frame())[0]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(preds.as_data_frame() > threshold)/(preds.shape[0] * 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_raw = pd.read_csv(\"../model-builder/resources/verify_20170202_2243.csv\")\n",
    "verify = verify_raw[[\" LinAccX (g)\",\" LinAccY (g)\",\" LinAccZ (g)\"]].as_matrix()\n",
    "verify = create_dataset(verify, look_back)\n",
    "verify_hex = h2o.H2OFrame(verify)\n",
    "verify_preds = model.predict(verify_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = list(verify_preds.as_data_frame()[\"predict\"])\n",
    "x = [i for i in range(len(v)) if abs(v[i]) > threshold]\n",
    "np.count_nonzero(verify_preds.as_data_frame() > threshold)/(verify_preds.shape[0] * 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(14, 7)\n",
    "\n",
    "plt.plot(list(range(len(iot_raw[\" LinAccX (g)\"]))), iot_raw[\" LinAccX (g)\"], \"go\")\n",
    "plt.ylabel('LinAccX')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(range(len(verify_raw[\" LinAccX (g)\"]))), verify_raw[\" LinAccX (g)\"], \"go\", x,verify_raw[\" LinAccX (g)\"][x], \"ro\")\n",
    "plt.ylabel('LinAccX')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(range(len(verify_raw[\" LinAccY (g)\"]))), verify_raw[\" LinAccY (g)\"], \"go\", x,verify_raw[\" LinAccY (g)\"][x], \"ro\")\n",
    "plt.ylabel('LinAccY')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(range(len(verify_raw[\" LinAccZ (g)\"]))), verify_raw[\" LinAccZ (g)\"], \"go\", x,verify_raw[\" LinAccZ (g)\"][x], \"ro\")\n",
    "plt.ylabel('LinAccZ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
