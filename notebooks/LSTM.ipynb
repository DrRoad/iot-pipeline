{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection using LSTM\n",
    "\n",
    "This notebook is an example for how to use Long-Short Term Memory neural networks for anomaly detection.\n",
    "\n",
    "Data used in this example is taken from hardware sensors attached to a robot arm performing simple tasks. We will be using 3 values - linear acceleration X/Y/Z. The goal is to predict robot malfunction before it crashes (and before a person is able to notice it).\n",
    "\n",
    "Network graph will be prepared using Keras/Tensorflow and the training itself will be performed using DeepWater."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required modules (h2o for deepwater and pandas for initial data munging).\n",
    "\n",
    "Bootstrap a single node H2O instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_112\"; Java(TM) SE Runtime Environment (build 1.8.0_112-b16); Java HotSpot(TM) 64-Bit Server VM (build 25.112-b16, mixed mode)\n",
      "  Starting server from /Users/mateusz/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/05/vvsycrl162zbzlh1wy8bdslh0000gn/T/tmpq_aml1fu\n",
      "  JVM stdout: /var/folders/05/vvsycrl162zbzlh1wy8bdslh0000gn/T/tmpq_aml1fu/h2o_mateusz_started_from_python.out\n",
      "  JVM stderr: /var/folders/05/vvsycrl162zbzlh1wy8bdslh0000gn/T/tmpq_aml1fu/h2o_mateusz_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n",
      "Warning: Your H2O cluster version is too old (5 months and 24 days)! Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>04 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.11.0.99999</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>5 months and 24 days !!!</td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_mateusz_1mv4hy</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.5.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O cluster uptime:         04 secs\n",
       "H2O cluster version:        3.11.0.99999\n",
       "H2O cluster version age:    5 months and 24 days !!!\n",
       "H2O cluster name:           H2O_from_python_mateusz_1mv4hy\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "Python version:             3.5.2 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.estimators.deepwater import H2ODeepWaterEstimator\n",
    "import pandas as pd\n",
    "\n",
    "h2o.init(port=54321, nthreads=-1)\n",
    "if not H2ODeepWaterEstimator.available(): exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom TF LSTM model\n",
    "\n",
    "Build a custom LSTM network graph using Keras and save it for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers import LSTM\n",
    "from keras import backend as K\n",
    "from keras.objectives import categorical_crossentropy\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "def keras_model(h, w):\n",
    "    classes = 1\n",
    "    # always create a new graph inside ipython or\n",
    "    # the default one will be used and can lead to\n",
    "    # unexpected behavior\n",
    "    graph = tf.Graph() \n",
    "    with graph.as_default():\n",
    "        size = w * h\n",
    "        # Input images fed via H2O\n",
    "        inp = tf.placeholder(tf.float32, [None, size])\n",
    "        # Actual labels used for training fed via H2O\n",
    "        labels = tf.placeholder(tf.float32, [None, classes])\n",
    "\n",
    "        # Keras network\n",
    "        x = Reshape((h, w))(inp)\n",
    "\n",
    "        x = LSTM(32, input_shape=(h, w))(x)\n",
    "        x = Reshape((h, classes))(x)\n",
    "        out = x\n",
    "\n",
    "        predictions = out\n",
    "\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels,logits=out))\n",
    "        train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "        init_op = tf.global_variables_initializer()\n",
    "\n",
    "        # Metadata required by H2O\n",
    "        tf.add_to_collection(ops.GraphKeys.INIT_OP, init_op.name)\n",
    "        tf.add_to_collection(ops.GraphKeys.TRAIN_OP, train_step)\n",
    "        tf.add_to_collection(\"logits\", out)\n",
    "        tf.add_to_collection(\"predictions\", predictions)\n",
    "\n",
    "        meta = json.dumps({\n",
    "                \"inputs\": {\"batch_image_input\": inp.name,\n",
    "                           \"categorical_labels\": labels.name},\n",
    "                \"outputs\": {\"categorical_logits\": out.name,\n",
    "                            \"layers\": ','.join([m.name for m in tf.get_default_graph().get_operations()])},\n",
    "                \"parameters\": {}\n",
    "            })\n",
    "        tf.add_to_collection(\"meta\", meta)\n",
    "\n",
    "        # Save the meta file with the graph\n",
    "        saver = tf.train.Saver()\n",
    "        filename = \"/tmp/keras_tf_lstm.meta\"\n",
    "        tf.train.export_meta_graph(filename, saver_def=saver.as_saver_def())\n",
    "\n",
    "        return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateusz/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Read training data into memory\n",
    "iot_raw = pd.read_csv('../model-builder/resources/normal_20170202_2229.csv')\n",
    "\n",
    "# Select training columns\n",
    "iot_train = iot_raw[[\" LinAccX (g)\",\" LinAccY (g)\",\" LinAccZ (g)\"]]\n",
    "\n",
    "y = iot_train.sum(axis=1)\n",
    "iot_train[\"y\"] = y\n",
    "\n",
    "# Send the data to H2O\n",
    "iot_train_frame  = h2o.H2OFrame(iot_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepwater Model Build progress: | (failed)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Job with key $03017f00000132d4ffffffff$_9abc1fac1e1fd656ae2b346aee704b99 failed with an exception: java.lang.IllegalArgumentException: cannot copy Tensor with 3 dimensions into an object with 2\nstacktrace: \njava.lang.IllegalArgumentException: cannot copy Tensor with 3 dimensions into an object with 2\n\tat org.tensorflow.Tensor.throwExceptionIfTypeIsIncompatible(Tensor.java:574)\n\tat org.tensorflow.Tensor.copyTo(Tensor.java:352)\n\tat deepwater.backends.tensorflow.models.TensorflowModel.getPredictions(TensorflowModel.java:81)\n\tat deepwater.backends.tensorflow.TensorflowBackend.predict(TensorflowBackend.java:446)\n\tat hex.deepwater.DeepWaterModelInfo.predict(DeepWaterModelInfo.java:67)\n\tat hex.deepwater.DeepWaterModel$DeepWaterBigScore.setupLocal(DeepWaterModel.java:827)\n\tat water.MRTask.setupLocal0(MRTask.java:550)\n\tat water.MRTask.dfork(MRTask.java:456)\n\tat water.MRTask.doAll(MRTask.java:389)\n\tat water.MRTask.doAll(MRTask.java:385)\n\tat hex.deepwater.DeepWaterModel.scoreMetrics(DeepWaterModel.java:946)\n\tat hex.deepwater.DeepWaterModel.doScoring(DeepWaterModel.java:368)\n\tat hex.deepwater.DeepWater$DeepWaterDriver.trainModel(DeepWater.java:353)\n\tat hex.deepwater.DeepWater$DeepWaterDriver.buildModel(DeepWater.java:205)\n\tat hex.deepwater.DeepWater$DeepWaterDriver.computeImpl(DeepWater.java:118)\n\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:169)\n\tat hex.deepwater.DeepWater$DeepWaterDriver.compute2(DeepWater.java:111)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1190)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4d3ed027bb15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tensorflow\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                              ) \n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\" LinAccX (g)\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" LinAccY (g)\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" LinAccZ (g)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miot_train_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mateusz/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h2o/estimators/estimator_base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, max_runtime_secs, ignored_columns, model_id)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET /%d/Models/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrest_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mateusz/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h2o/job.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"stacktrace\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 raise EnvironmentError(\"Job with key {} failed with an exception: {}\\nstacktrace: \"\n\u001b[0;32m---> 73\u001b[0;31m                                        \"\\n{}\".format(self.job_key, self.exception, self.job[\"stacktrace\"]))\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job with key %s failed with an exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Job with key $03017f00000132d4ffffffff$_9abc1fac1e1fd656ae2b346aee704b99 failed with an exception: java.lang.IllegalArgumentException: cannot copy Tensor with 3 dimensions into an object with 2\nstacktrace: \njava.lang.IllegalArgumentException: cannot copy Tensor with 3 dimensions into an object with 2\n\tat org.tensorflow.Tensor.throwExceptionIfTypeIsIncompatible(Tensor.java:574)\n\tat org.tensorflow.Tensor.copyTo(Tensor.java:352)\n\tat deepwater.backends.tensorflow.models.TensorflowModel.getPredictions(TensorflowModel.java:81)\n\tat deepwater.backends.tensorflow.TensorflowBackend.predict(TensorflowBackend.java:446)\n\tat hex.deepwater.DeepWaterModelInfo.predict(DeepWaterModelInfo.java:67)\n\tat hex.deepwater.DeepWaterModel$DeepWaterBigScore.setupLocal(DeepWaterModel.java:827)\n\tat water.MRTask.setupLocal0(MRTask.java:550)\n\tat water.MRTask.dfork(MRTask.java:456)\n\tat water.MRTask.doAll(MRTask.java:389)\n\tat water.MRTask.doAll(MRTask.java:385)\n\tat hex.deepwater.DeepWaterModel.scoreMetrics(DeepWaterModel.java:946)\n\tat hex.deepwater.DeepWaterModel.doScoring(DeepWaterModel.java:368)\n\tat hex.deepwater.DeepWater$DeepWaterDriver.trainModel(DeepWater.java:353)\n\tat hex.deepwater.DeepWater$DeepWaterDriver.buildModel(DeepWater.java:205)\n\tat hex.deepwater.DeepWater$DeepWaterDriver.computeImpl(DeepWater.java:118)\n\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:169)\n\tat hex.deepwater.DeepWater$DeepWaterDriver.compute2(DeepWater.java:111)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1190)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "(h, w) = iot_train.shape\n",
    "model_filename = keras_model(batch_size, w-1)\n",
    "model = H2ODeepWaterEstimator(epochs=500, \n",
    "                              network_definition_file=model_filename,\n",
    "                              backend=\"tensorflow\", \n",
    "                             ) \n",
    "model.train(x = [\" LinAccX (g)\",\" LinAccY (g)\",\" LinAccZ (g)\"], y = 3, training_frame=iot_train_frame)\n",
    "model.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
