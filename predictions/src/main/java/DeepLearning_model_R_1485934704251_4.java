/*
  Licensed under the Apache License, Version 2.0
    http://www.apache.org/licenses/LICENSE-2.0.html

  AUTOGENERATED BY H2O at 2017-02-02T19:07:12.142+09:00
  3.10.2.2
  
  Standalone prediction code with sample test data for DeepLearningModel named DeepLearning_model_R_1485934704251_4

  How to download, compile and execute:
      mkdir tmpdir
      cd tmpdir
      curl http:/localhost/127.0.0.1:54321/3/h2o-genmodel.jar > h2o-genmodel.jar
      curl http:/localhost/127.0.0.1:54321/3/Models.java/DeepLearning_model_R_1485934704251_4 > DeepLearning_model_R_1485934704251_4.java
      javac -cp h2o-genmodel.jar -J-Xmx2g -J-XX:MaxPermSize=128m DeepLearning_model_R_1485934704251_4.java

     (Note:  Try java argument -XX:+PrintCompilation to show runtime JIT compiler behavior.)
*/
import java.util.Map;
import hex.genmodel.GenModel;
import hex.genmodel.annotations.ModelPojo;

@ModelPojo(name="DeepLearning_model_R_1485934704251_4", algorithm="deeplearning")
public class DeepLearning_model_R_1485934704251_4 extends GenModel {
  public hex.ModelCategory getModelCategory() { return hex.ModelCategory.AutoEncoder; }
  public boolean isSupervised() { return false; }
  public int nfeatures() { return 3; }
  public int nclasses() { return 3; }
  // Thread-local storage for input neuron activation values.
  final double[] NUMS = new double[3];
  static class NORMMUL implements java.io.Serializable {
    public static final double[] VALUES = new double[3];
    static {
      NORMMUL_0.fill(VALUES);
    }
    static final class NORMMUL_0 implements java.io.Serializable {
      static final void fill(double[] sa) {
        sa[0] = 0.9556574923547398;
        sa[1] = 1.2748597654258031;
        sa[2] = 1.721763085399449;
      }
    }
}
  static class NORMSUB implements java.io.Serializable {
    public static final double[] VALUES = new double[3];
    static {
      NORMSUB_0.fill(VALUES);
    }
    static final class NORMSUB_0 implements java.io.Serializable {
      static final void fill(double[] sa) {
        sa[0] = 0.002058331852783207;
        sa[1] = 0.005036394199887934;
        sa[2] = -0.0037912752319908148;
      }
    }
}
  // Workspace for categorical offsets.
  public static final int[] CATOFFSETS = {0};
  // Hidden layer dropout ratios.
  public static final double[] HIDDEN_DROPOUT_RATIOS = {0.5};
  // Number of neurons for each layer.
  public static final int[] NEURONS = {3,50,3};
    public int getPredsSize() { return 3; }
    public boolean isAutoEncoder() { return true; }
    public String getHeader() { return "reconstr_V1,reconstr_V2,reconstr_V3"; }
    // Thread-local storage for neuron activation values.
    final double[][] ACTIVATION = new double[][] {
      /* Input */ DeepLearning_model_R_1485934704251_4_Activation_0.VALUES,
      /* TanhDropout */ DeepLearning_model_R_1485934704251_4_Activation_1.VALUES,
      /* Tanh */ DeepLearning_model_R_1485934704251_4_Activation_2.VALUES
    };
    // Neuron bias values.
    public static final double[][] BIAS = new double[][] {
      /* Input */ DeepLearning_model_R_1485934704251_4_Bias_0.VALUES,
      /* TanhDropout */ DeepLearning_model_R_1485934704251_4_Bias_1.VALUES,
      /* Tanh */ DeepLearning_model_R_1485934704251_4_Bias_2.VALUES
    };
    // Connecting weights between neurons.
    public static final float[][] WEIGHT = new float[][] {
      /* Input */ DeepLearning_model_R_1485934704251_4_Weight_0.VALUES,
      /* TanhDropout */ DeepLearning_model_R_1485934704251_4_Weight_1.VALUES,
      /* Tanh */ DeepLearning_model_R_1485934704251_4_Weight_2.VALUES
    };

  // Names of columns used by model.
  public static final String[] NAMES = NamesHolder_DeepLearning_model_R_1485934704251_4.VALUES;

  // Column domains. The last array contains domain of response column.
  public static final String[][] DOMAINS = new String[][] {
    /* V1 */ null,
    /* V2 */ null,
    /* V3 */ null
  };

  public DeepLearning_model_R_1485934704251_4() { super(NAMES,DOMAINS); }
  public String getUUID() { return Long.toString(-3653978467933595532L); }

  // Pass in data in a double[], pre-aligned to the Model's requirements.
  // Jam predictions into the preds[] array; preds[0] is reserved for the
  // main prediction (class for classifiers or value for regression),
  // and remaining columns hold a probability distribution for classifiers.
  public final double[] score0( double[] data, double[] preds ) {
    java.util.Arrays.fill(preds,0);
    java.util.Arrays.fill(NUMS,0);
    int i = 0, ncats = 0;
    final int n = data.length;
    for(; i<n; ++i) {
      NUMS[i] = Double.isNaN(data[i]) ? 0 : (data[i] - NORMSUB.VALUES[i])*NORMMUL.VALUES[i];
    }
    java.util.Arrays.fill(ACTIVATION[0],0);
    for (i=0; i<NUMS.length; ++i) {
      ACTIVATION[0][CATOFFSETS[CATOFFSETS.length-1] + i] = Double.isNaN(NUMS[i]) ? 0 : NUMS[i];
    }
    for (i=1; i<ACTIVATION.length; ++i) {
      java.util.Arrays.fill(ACTIVATION[i],0);
      int cols = ACTIVATION[i-1].length;
      int rows = ACTIVATION[i].length;
      int extra=cols-cols%8;
      int multiple = (cols/8)*8-1;
      int idx = 0;
      float[] a = WEIGHT[i];
      double[] x = ACTIVATION[i-1];
      double[] y = BIAS[i];
      double[] res = ACTIVATION[i];
      for (int row=0; row<rows; ++row) {
        double psum0 = 0, psum1 = 0, psum2 = 0, psum3 = 0, psum4 = 0, psum5 = 0, psum6 = 0, psum7 = 0;
        for (int col = 0; col < multiple; col += 8) {
          int off = idx + col;
          psum0 += a[off    ] * x[col    ];
          psum1 += a[off + 1] * x[col + 1];
          psum2 += a[off + 2] * x[col + 2];
          psum3 += a[off + 3] * x[col + 3];
          psum4 += a[off + 4] * x[col + 4];
          psum5 += a[off + 5] * x[col + 5];
          psum6 += a[off + 6] * x[col + 6];
          psum7 += a[off + 7] * x[col + 7];
        }
        res[row] += psum0 + psum1 + psum2 + psum3;
        res[row] += psum4 + psum5 + psum6 + psum7;
        for (int col = extra; col < cols; col++)
          res[row] += a[idx + col] * x[col];
        res[row] += y[row];
        idx += cols;
      }
      if (i<=ACTIVATION.length-1) {
        for (int r=0; r<ACTIVATION[i].length; ++r) {
          ACTIVATION[i][r] = 1 - 2 / (1 + Math.exp(2*ACTIVATION[i][r]));
          if (i<ACTIVATION.length-1) {
            ACTIVATION[i][r] *= 1 - HIDDEN_DROPOUT_RATIOS[i-1];
          }
        }
      }
      if (i == ACTIVATION.length-1) {
        for (int r=0; r<ACTIVATION[i].length; r++) {
          if (Double.isNaN(ACTIVATION[i][r]))
            throw new RuntimeException("Numerical instability, reconstructed NaN.");
          preds[r] = ACTIVATION[i][r];
        }
        for (int k=0; k<3; ++k) {
          preds[k] = preds[k] / NORMMUL.VALUES[k-0] + NORMSUB.VALUES[k-0];
        }
      }
    }
    return preds;
  }
}
// Neuron activation values for Input layer
class DeepLearning_model_R_1485934704251_4_Activation_0 implements java.io.Serializable {
  public static final double[] VALUES = new double[3];
  static {
    DeepLearning_model_R_1485934704251_4_Activation_0_0.fill(VALUES);
  }
  static final class DeepLearning_model_R_1485934704251_4_Activation_0_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
    }
  }
}
// Neuron activation values for TanhDropout layer
class DeepLearning_model_R_1485934704251_4_Activation_1 implements java.io.Serializable {
  public static final double[] VALUES = new double[50];
  static {
    DeepLearning_model_R_1485934704251_4_Activation_1_0.fill(VALUES);
  }
  static final class DeepLearning_model_R_1485934704251_4_Activation_1_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
      sa[3] = 0.0;
      sa[4] = 0.0;
      sa[5] = 0.0;
      sa[6] = 0.0;
      sa[7] = 0.0;
      sa[8] = 0.0;
      sa[9] = 0.0;
      sa[10] = 0.0;
      sa[11] = 0.0;
      sa[12] = 0.0;
      sa[13] = 0.0;
      sa[14] = 0.0;
      sa[15] = 0.0;
      sa[16] = 0.0;
      sa[17] = 0.0;
      sa[18] = 0.0;
      sa[19] = 0.0;
      sa[20] = 0.0;
      sa[21] = 0.0;
      sa[22] = 0.0;
      sa[23] = 0.0;
      sa[24] = 0.0;
      sa[25] = 0.0;
      sa[26] = 0.0;
      sa[27] = 0.0;
      sa[28] = 0.0;
      sa[29] = 0.0;
      sa[30] = 0.0;
      sa[31] = 0.0;
      sa[32] = 0.0;
      sa[33] = 0.0;
      sa[34] = 0.0;
      sa[35] = 0.0;
      sa[36] = 0.0;
      sa[37] = 0.0;
      sa[38] = 0.0;
      sa[39] = 0.0;
      sa[40] = 0.0;
      sa[41] = 0.0;
      sa[42] = 0.0;
      sa[43] = 0.0;
      sa[44] = 0.0;
      sa[45] = 0.0;
      sa[46] = 0.0;
      sa[47] = 0.0;
      sa[48] = 0.0;
      sa[49] = 0.0;
    }
  }
}
// Neuron activation values for Tanh layer
class DeepLearning_model_R_1485934704251_4_Activation_2 implements java.io.Serializable {
  public static final double[] VALUES = new double[3];
  static {
    DeepLearning_model_R_1485934704251_4_Activation_2_0.fill(VALUES);
  }
  static final class DeepLearning_model_R_1485934704251_4_Activation_2_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 0.0;
      sa[1] = 0.0;
      sa[2] = 0.0;
    }
  }
}
// Neuron bias values for Input layer
class DeepLearning_model_R_1485934704251_4_Bias_0 implements java.io.Serializable {
  public static final double[] VALUES = null;
}
// Neuron bias values for TanhDropout layer
class DeepLearning_model_R_1485934704251_4_Bias_1 implements java.io.Serializable {
  public static final double[] VALUES = new double[50];
  static {
    DeepLearning_model_R_1485934704251_4_Bias_1_0.fill(VALUES);
  }
  static final class DeepLearning_model_R_1485934704251_4_Bias_1_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = 3.281068663917475E-4;
      sa[1] = -0.0012741188023854422;
      sa[2] = 8.080414682803453E-4;
      sa[3] = 5.329293216925464E-4;
      sa[4] = -4.469549047954798E-6;
      sa[5] = 9.816020818895245E-4;
      sa[6] = -1.6079984719498917E-4;
      sa[7] = 8.421322346037266E-4;
      sa[8] = 0.003047847576630265;
      sa[9] = 0.0013144195067099182;
      sa[10] = 0.0016522165220584572;
      sa[11] = -8.935228080457539E-4;
      sa[12] = -0.0011700746619790702;
      sa[13] = -2.555200774487219E-4;
      sa[14] = -0.0027605902398137256;
      sa[15] = -0.0018438604329564776;
      sa[16] = 0.0013409313854933613;
      sa[17] = -0.0010286769243545483;
      sa[18] = 0.0023503879342954954;
      sa[19] = 2.82404240892167E-4;
      sa[20] = 6.500242170677457E-4;
      sa[21] = 4.824091888190184E-5;
      sa[22] = 2.280883298212308E-4;
      sa[23] = 4.146732562327408E-4;
      sa[24] = 9.438368856283861E-4;
      sa[25] = -0.0012373502713543174;
      sa[26] = -1.3153776959486324E-4;
      sa[27] = -0.001669342361575386;
      sa[28] = 0.001429274428171316;
      sa[29] = 4.915662129963674E-4;
      sa[30] = 0.0020316351602085434;
      sa[31] = 6.316599033875627E-4;
      sa[32] = -7.513153147229951E-4;
      sa[33] = 3.9642256708340303E-4;
      sa[34] = -0.00128705090015402;
      sa[35] = 3.154184485724904E-4;
      sa[36] = 4.3043711501945667E-4;
      sa[37] = -6.078485629305775E-4;
      sa[38] = -6.940986925546597E-4;
      sa[39] = -5.850086172976693E-5;
      sa[40] = -2.855923528461646E-4;
      sa[41] = -7.032385598649852E-4;
      sa[42] = 0.0010454654826719165;
      sa[43] = -0.0024898013110519262;
      sa[44] = 0.002647543132776646;
      sa[45] = 5.621982327678951E-4;
      sa[46] = 1.7715774683580037E-5;
      sa[47] = -9.678861274578179E-4;
      sa[48] = -3.4761521053005185E-4;
      sa[49] = -1.478018098613486E-6;
    }
  }
}
// Neuron bias values for Tanh layer
class DeepLearning_model_R_1485934704251_4_Bias_2 implements java.io.Serializable {
  public static final double[] VALUES = new double[3];
  static {
    DeepLearning_model_R_1485934704251_4_Bias_2_0.fill(VALUES);
  }
  static final class DeepLearning_model_R_1485934704251_4_Bias_2_0 implements java.io.Serializable {
    static final void fill(double[] sa) {
      sa[0] = -7.651202836625882E-5;
      sa[1] = 0.002047358924556081;
      sa[2] = -0.002225864756642507;
    }
  }
}
class DeepLearning_model_R_1485934704251_4_Weight_0 implements java.io.Serializable {
  public static final float[] VALUES = null;
}
// Neuron weights connecting Input and TanhDropout layer
class DeepLearning_model_R_1485934704251_4_Weight_1 implements java.io.Serializable {
  public static final float[] VALUES = new float[150];
  static {
    DeepLearning_model_R_1485934704251_4_Weight_1_0.fill(VALUES);
  }
  static final class DeepLearning_model_R_1485934704251_4_Weight_1_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = -7.753576E-4f;
      sa[1] = 1.5506921f;
      sa[2] = -4.4467134E-4f;
      sa[3] = 1.6344993f;
      sa[4] = 9.2828326E-4f;
      sa[5] = -9.958316E-4f;
      sa[6] = 4.3335074E-4f;
      sa[7] = -5.752464E-4f;
      sa[8] = -1.6615789f;
      sa[9] = -0.0011065319f;
      sa[10] = 1.5487098f;
      sa[11] = -4.3460366E-4f;
      sa[12] = 1.1598342E-7f;
      sa[13] = 2.8917853E-8f;
      sa[14] = 3.911173E-6f;
      sa[15] = -1.6046951f;
      sa[16] = -0.0012959399f;
      sa[17] = 2.0845457E-4f;
      sa[18] = 0.0011350426f;
      sa[19] = -5.6948344E-4f;
      sa[20] = -1.6173061f;
      sa[21] = -1.6396619f;
      sa[22] = -0.0019887476f;
      sa[23] = 4.6689205E-5f;
      sa[24] = -1.6263387f;
      sa[25] = -0.0017644066f;
      sa[26] = 2.64808E-4f;
      sa[27] = 4.894217E-4f;
      sa[28] = -5.7286664E-4f;
      sa[29] = -1.624859f;
      sa[30] = -0.0011441269f;
      sa[31] = 1.5382837f;
      sa[32] = -2.8312285E-4f;
      sa[33] = -7.8676E-4f;
      sa[34] = 3.061986E-4f;
      sa[35] = 1.6478661f;
      sa[36] = 0.0013939447f;
      sa[37] = -1.5110834f;
      sa[38] = 3.138813E-4f;
      sa[39] = -1.224408E-4f;
      sa[40] = 5.2439584E-4f;
      sa[41] = 1.6073265f;
      sa[42] = 1.6478297f;
      sa[43] = 0.0022531073f;
      sa[44] = -2.3986328E-4f;
      sa[45] = -5.3104537E-4f;
      sa[46] = -7.26033E-5f;
      sa[47] = 1.67194f;
      sa[48] = 5.760968E-4f;
      sa[49] = -5.801198E-4f;
      sa[50] = -1.6263299f;
      sa[51] = -7.926862E-4f;
      sa[52] = 1.6097552f;
      sa[53] = -2.723308E-4f;
      sa[54] = 0.0011172293f;
      sa[55] = 1.20410215E-4f;
      sa[56] = -1.66911f;
      sa[57] = -1.6386969f;
      sa[58] = -0.0015330147f;
      sa[59] = -1.8068614E-4f;
      sa[60] = -5.014718E-4f;
      sa[61] = 1.5245229f;
      sa[62] = -2.8809273E-4f;
      sa[63] = -0.0012975058f;
      sa[64] = 1.5444014f;
      sa[65] = -2.9302054E-4f;
      sa[66] = -1.6424881f;
      sa[67] = -5.2008058E-5f;
      sa[68] = 4.583634E-5f;
      sa[69] = -0.0012850476f;
      sa[70] = 1.5420017f;
      sa[71] = -3.6742602E-4f;
      sa[72] = 6.240822E-4f;
      sa[73] = -6.087117E-4f;
      sa[74] = -1.6328319f;
      sa[75] = -4.001672E-4f;
      sa[76] = 6.0218485E-4f;
      sa[77] = 1.5932668f;
      sa[78] = 6.1354117E-4f;
      sa[79] = -1.5202903f;
      sa[80] = 3.893956E-4f;
      sa[81] = 1.6539797f;
      sa[82] = 6.478461E-4f;
      sa[83] = 2.3874425E-5f;
      sa[84] = -1.6064091f;
      sa[85] = -0.001536782f;
      sa[86] = 2.9339956E-4f;
      sa[87] = -5.618858E-4f;
      sa[88] = 1.4983387f;
      sa[89] = -2.925706E-4f;
      sa[90] = 6.6446816E-4f;
      sa[91] = 9.469724E-4f;
      sa[92] = -1.6212418f;
      sa[93] = -0.0010892682f;
      sa[94] = 1.5160087f;
      sa[95] = -4.2629128E-4f;
      sa[96] = -0.001216813f;
      sa[97] = 1.5360575f;
      sa[98] = -3.1784494E-4f;
      sa[99] = -0.001007012f;
      sa[100] = 1.5409136f;
      sa[101] = -3.147375E-4f;
      sa[102] = -6.814049E-4f;
      sa[103] = 6.658322E-4f;
      sa[104] = 1.6126528f;
      sa[105] = -1.6618445f;
      sa[106] = -7.216478E-4f;
      sa[107] = 2.68885E-4f;
      sa[108] = -8.128742E-4f;
      sa[109] = 1.553689f;
      sa[110] = -5.274633E-4f;
      sa[111] = 1.6460155f;
      sa[112] = 3.798973E-4f;
      sa[113] = -1.0610757E-4f;
      sa[114] = -6.6376885E-4f;
      sa[115] = 5.648099E-4f;
      sa[116] = 1.6307559f;
      sa[117] = 1.6441462f;
      sa[118] = 0.001162447f;
      sa[119] = -4.433074E-4f;
      sa[120] = -9.046645E-4f;
      sa[121] = 1.54706f;
      sa[122] = -3.273702E-4f;
      sa[123] = -0.0010703463f;
      sa[124] = 6.5937155E-4f;
      sa[125] = 1.6322014f;
      sa[126] = -0.0010464909f;
      sa[127] = 1.5751557f;
      sa[128] = -3.5178295E-4f;
      sa[129] = -5.292122E-4f;
      sa[130] = 3.4271067E-4f;
      sa[131] = 1.6092787f;
      sa[132] = -1.6757102f;
      sa[133] = -6.3474657E-4f;
      sa[134] = 1.8950184E-4f;
      sa[135] = -0.001685169f;
      sa[136] = 6.2224304E-4f;
      sa[137] = 1.618645f;
      sa[138] = -5.888085E-4f;
      sa[139] = 1.5405211f;
      sa[140] = -3.3353185E-4f;
      sa[141] = 1.6091607f;
      sa[142] = 0.0011373397f;
      sa[143] = -2.006589E-4f;
      sa[144] = 8.578564E-4f;
      sa[145] = -1.5606681f;
      sa[146] = 8.3085574E-4f;
      sa[147] = 6.6882635E-8f;
      sa[148] = 6.416712E-6f;
      sa[149] = -6.7384044E-6f;
    }
  }
}
// Neuron weights connecting TanhDropout and Tanh layer
class DeepLearning_model_R_1485934704251_4_Weight_2 implements java.io.Serializable {
  public static final float[] VALUES = new float[150];
  static {
    DeepLearning_model_R_1485934704251_4_Weight_2_0.fill(VALUES);
  }
  static final class DeepLearning_model_R_1485934704251_4_Weight_2_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 0.007539261f;
      sa[1] = 0.08500814f;
      sa[2] = -0.0016697292f;
      sa[3] = -8.9910295E-4f;
      sa[4] = -5.091759E-6f;
      sa[5] = -0.08233675f;
      sa[6] = 0.008134667f;
      sa[7] = -0.09136737f;
      sa[8] = -0.08267478f;
      sa[9] = 0.0013592505f;
      sa[10] = -0.005726595f;
      sa[11] = -0.001469544f;
      sa[12] = 0.005778229f;
      sa[13] = 0.0024729047f;
      sa[14] = 0.07795748f;
      sa[15] = -0.0011420503f;
      sa[16] = -0.0012701971f;
      sa[17] = 8.08403E-5f;
      sa[18] = 0.0046909503f;
      sa[19] = -0.083329245f;
      sa[20] = 0.0012097148f;
      sa[21] = -0.004439177f;
      sa[22] = -0.07272812f;
      sa[23] = -0.0017615531f;
      sa[24] = 0.0025691325f;
      sa[25] = 0.0019873204f;
      sa[26] = -0.0029928826f;
      sa[27] = 0.08128872f;
      sa[28] = -0.0844419f;
      sa[29] = 0.010895397f;
      sa[30] = 0.0034567933f;
      sa[31] = -0.0025117295f;
      sa[32] = -0.0034724346f;
      sa[33] = -0.0026309094f;
      sa[34] = -0.0028451781f;
      sa[35] = -0.08714005f;
      sa[36] = 0.0042806715f;
      sa[37] = 0.07661246f;
      sa[38] = -1.7065724E-4f;
      sa[39] = 0.08634843f;
      sa[40] = 0.0015011467f;
      sa[41] = -0.0027482596f;
      sa[42] = 0.0022605155f;
      sa[43] = 0.003048176f;
      sa[44] = -0.08637093f;
      sa[45] = -0.010534061f;
      sa[46] = 0.002227528f;
      sa[47] = 0.07684405f;
      sa[48] = -0.005315409f;
      sa[49] = 6.1430337E-6f;
      sa[50] = 0.076371655f;
      sa[51] = -0.0022362273f;
      sa[52] = -0.0021738785f;
      sa[53] = 0.072366714f;
      sa[54] = -1.24106E-6f;
      sa[55] = -0.0010097916f;
      sa[56] = -0.008593233f;
      sa[57] = -0.006377786f;
      sa[58] = -5.1293435E-4f;
      sa[59] = 0.0010384625f;
      sa[60] = 0.06161694f;
      sa[61] = -0.0031955482f;
      sa[62] = -0.07110755f;
      sa[63] = -0.004607198f;
      sa[64] = 0.00853286f;
      sa[65] = -0.0061338875f;
      sa[66] = -0.0011203991f;
      sa[67] = 0.06752934f;
      sa[68] = 0.0011344424f;
      sa[69] = -8.12298E-4f;
      sa[70] = 0.061374575f;
      sa[71] = 0.06809861f;
      sa[72] = 0.0054065697f;
      sa[73] = 0.074065134f;
      sa[74] = -0.0030509676f;
      sa[75] = -0.003286613f;
      sa[76] = -0.06796859f;
      sa[77] = -0.0010190834f;
      sa[78] = -0.002945305f;
      sa[79] = 0.068851426f;
      sa[80] = 0.011920954f;
      sa[81] = 0.06981967f;
      sa[82] = 0.068453595f;
      sa[83] = 0.061665818f;
      sa[84] = 0.0028449353f;
      sa[85] = 0.0057076537f;
      sa[86] = 0.077622175f;
      sa[87] = -0.0039128275f;
      sa[88] = 0.0019187864f;
      sa[89] = -0.0020305244f;
      sa[90] = 0.07645697f;
      sa[91] = 0.0070440816f;
      sa[92] = 0.07556148f;
      sa[93] = -0.005300807f;
      sa[94] = 0.0033438418f;
      sa[95] = 0.0030875509f;
      sa[96] = 0.06694718f;
      sa[97] = -7.4251875E-4f;
      sa[98] = -0.07761942f;
      sa[99] = -8.841354E-6f;
      sa[100] = -0.0019162628f;
      sa[101] = -0.009747666f;
      sa[102] = -0.07867039f;
      sa[103] = -0.006947181f;
      sa[104] = -6.209776E-6f;
      sa[105] = 0.003005916f;
      sa[106] = -0.06954684f;
      sa[107] = 0.0055547683f;
      sa[108] = 0.008435125f;
      sa[109] = -0.07435037f;
      sa[110] = -0.0016799431f;
      sa[111] = 0.070267685f;
      sa[112] = 2.9286562E-4f;
      sa[113] = 0.06976128f;
      sa[114] = -0.0056076115f;
      sa[115] = 0.078437254f;
      sa[116] = -0.083653495f;
      sa[117] = 0.0041433666f;
      sa[118] = -0.08860706f;
      sa[119] = -0.0058167027f;
      sa[120] = -0.001360502f;
      sa[121] = 0.00127296f;
      sa[122] = -0.0046975487f;
      sa[123] = -4.0185964E-4f;
      sa[124] = -0.0640332f;
      sa[125] = 0.07638222f;
      sa[126] = 0.0039103962f;
      sa[127] = 2.1500737E-4f;
      sa[128] = 0.0029135956f;
      sa[129] = 0.0031925507f;
      sa[130] = -0.08727771f;
      sa[131] = -0.0042573977f;
      sa[132] = 0.001502605f;
      sa[133] = -0.0027934208f;
      sa[134] = 0.07501991f;
      sa[135] = 0.0045228815f;
      sa[136] = -0.0062873573f;
      sa[137] = -3.5684655E-4f;
      sa[138] = 0.064757854f;
      sa[139] = -0.009712412f;
      sa[140] = 0.00751487f;
      sa[141] = 0.075559855f;
      sa[142] = 0.002501572f;
      sa[143] = 0.07666824f;
      sa[144] = 0.0048457347f;
      sa[145] = 0.07684814f;
      sa[146] = -9.078215E-4f;
      sa[147] = -0.0070176995f;
      sa[148] = 0.016849311f;
      sa[149] = -6.4922E-6f;
    }
  }
}
// The class representing training column names
class NamesHolder_DeepLearning_model_R_1485934704251_4 implements java.io.Serializable {
  public static final String[] VALUES = new String[3];
  static {
    NamesHolder_DeepLearning_model_R_1485934704251_4_0.fill(VALUES);
  }
  static final class NamesHolder_DeepLearning_model_R_1485934704251_4_0 implements java.io.Serializable {
    static final void fill(String[] sa) {
      sa[0] = "V1";
      sa[1] = "V2";
      sa[2] = "V3";
    }
  }
}


